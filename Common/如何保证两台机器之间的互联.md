# 使用DeepSpeed时，如何保证两台机器能够互联？

对于其他分布式的操作也是类似的，如pytorch等。

<br><br>

## 如何让多台LINUX主机无密码ssh连接？

首先我们要保证两台机器能够ssh互联：操作步骤如下：

### 链接步骤

* 使用`sudo su`时，是在`root`用户下进行的操作，`ssh-keygen -t rsa`操作的`.ssh`目录默认是放在`/root/.ssh`目录下的，如果是指定用户，则默认的操作目录是`~/.ssh`。区别在于，我们通过ssh无密码能够链接的节点也不一样：`root@ip`和`username@ip`的区别。

* 为了保证两台机器互联，需要保证A机器的公钥`id_rsa.pub`的内容放到B机器的`authorized_keys`的文件中，同时B机器的公钥`id_rsa.pub`的内容也要放到A机器的`authorized_keys`的文件中。多台机器互联的操作也是类似的，我们可以建立一份`authorized_keys`文件，包含所有机器的公钥`id_rsa.pub`内的内容，然后再把`authorized_keys`文件copy到所有需要参与互联的机器。

### 可能出现的问题及解决方案

进行了上述步骤之后，从一台机器还是不能直接访问另一台机器或是不能访问另一台机器的某个接口，可能报类似的错误`[c10d] The client socket has failed to connect to (errno: 113 - No route to host).`，我们可以简单的关闭防火墙, 比如如下操作，参见[Python 2.7 [Errno 113] No route to host](https://stackoverflow.com/questions/39063817/python-2-7-errno-113-no-route-to-host)：

```
(base) rtx@rtxA6000:~$ service firewalld stop
==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ===
Authentication is required to stop 'firewalld.service'.
Authenticating as: rtx,,, (rtx)
Password:
==== AUTHENTICATION COMPLETE ===
```
这里需要注意的是，当我们去搜索关闭防火墙的时候，会有`sudo ufw disable`这样的操作，参见[启用和阻止防火墙访问 - Ubuntu](http://people.ubuntu.com/~happyaron/ubuntu-docs/precise-html/net-firewall-on-off.html)或[Ubuntu中防火墙的使用和开放、关闭端口](https://blog.csdn.net/willingtolove/article/details/109863064)，如果这种方法不奏效，那么还是使用上述的方法。


### Ref:
1. [ubuntu设置远程无密码登录ssh秘钥认证](https://blog.csdn.net/xyh930929/article/details/84531081)
2. [多台Linux主机无需密码直接连接的SSH配置](https://blog.csdn.net/hq86937375/article/details/69218201)
3. [测试Linux端口的连通性的四种方法](https://blog.csdn.net/lzxomg/article/details/76349887)
4. []


<br><br>

## 测试

参见：[How to use DeepSpeed](https://huggingface.co/docs/accelerate/usage_guides/deepspeed#deepspeed-zero-inference)

我使用了其中很少的代码，即`test.py`文件, 然后通过`accelerate launch test.py`进行调用：

```
from accelerate import Accelerator
from accelerate.state import AcceleratorState


def main():
    accelerator = Accelerator()
    accelerator.print(f"{AcceleratorState()}")


if __name__ == "__main__":
    main()
```

`accelerate launch test.py`其实就是测试通过`accelerate config`所做的设置是否合理，我的`accelerate config`里配置了两台机器（即两个节点），那么我在两台机器上同时运行`accelerate launch test.py` (两台机器上我都copy了同样的`test.py`文件)，正常运行则证明了能够同时使用两台机器做分布式。

### 第一个节点的设置如下：`config env`:

```
(lavis) rtx@rtxA6000:~/workspace/code/demo/transformer$ accelerate env

Copy-and-paste the text below in your GitHub issue

- `Accelerate` version: 0.17.0
- Platform: Linux-5.4.0-139-generic-x86_64-with-glibc2.17
- Python version: 3.8.16
- Numpy version: 1.24.2
- PyTorch version (GPU?): 1.13.1+cu117 (True)
- `Accelerate` default config:
        - compute_environment: LOCAL_MACHINE
        - distributed_type: DEEPSPEED
        - mixed_precision: bf16
        - use_cpu: False
        - num_processes: 3
        - machine_rank: 0
        - num_machines: 2
        - main_process_ip: 10.19.206.249
        - main_process_port: 10001
        - rdzv_backend: static
        - same_network: False
        - main_training_function: main
        - deepspeed_config: {'deepspeed_multinode_launcher': 'standard', 'gradient_accumulation_steps': 1, 'offload_optimizer_device': 'cpu', 'offload_param_device': 'cpu', 'zero3_init_flag': False, 'zero3_save_16bit_model': False, 'zero_stage': 3}
        - fsdp_config: {}
        - megatron_lm_config: {}
        - downcast_bf16: no
        - tpu_use_cluster: False
        - tpu_use_sudo: False
        - tpu_env: []
        - dynamo_config: {}

```

### 第一个节点的设置如下：`config env`:

```
accelerate env

Copy-and-paste the text below in your GitHub issue

- `Accelerate` version: 0.17.1
- Platform: Linux-5.15.0-58-generic-x86_64-with-glibc2.17
- Python version: 3.8.16
- Numpy version: 1.24.2
- PyTorch version (GPU?): 1.13.1+cu117 (True)
- `Accelerate` default config:
        - compute_environment: LOCAL_MACHINE
        - distributed_type: DEEPSPEED
        - mixed_precision: no
        - use_cpu: False
        - num_processes: 3
        - machine_rank: 1
        - num_machines: 2
        - main_process_ip: 10.19.206.249
        - main_process_port: 10001
        - rdzv_backend: static
        - same_network: False
        - main_training_function: main
        - deepspeed_config: {'deepspeed_multinode_launcher': 'standard', 'gradient_accumulation_steps': 1, 'offload_optimizer_device': 'cpu', 'offload_param_device': 'cpu', 'zero3_init_flag': False, 'zero3_save_16bit_model': False, 'zero_stage': 3}
        - fsdp_config: {}
        - megatron_lm_config: {}
        - downcast_bf16: no
        - tpu_use_cluster: False
        - tpu_use_sudo: False
        - tpu_env: []
        - dynamo_config: {}

```

### 同时运行`accelerate launch test.py`

### 第一个节点显示：

```
(lavis) rtx@rtxA6000:~/workspace/code/demo/transformer$ accelerate launch test.py
[21:38:49] WARNING  The following values were not passed to `accelerate launch` and had defaults used instead:                                     launch.py:887
                            `--dynamo_backend` was set to a value of `'no'`
                    To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
Distributed environment: DEEPSPEED
Num processes: 2
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}

```

### 第二个节点显示：

```
accelerate launch test.py
The following values were not passed to `accelerate launch` and had defaults used instead:
        `--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
Distributed environment: DEEPSPEED
Num processes: 2
Process index: 1
Local process index: 0
Device: cuda:0

Mixed precision type: no
ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': False}, 'bf16': {'enabled': False}}

```

上述试验已经实现两个节点的通路。

