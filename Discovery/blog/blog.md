# BLOG

## [ChatGPT for Drug Development? How Large Language Models Are Changing Drug Discovery](https://vial.com/blog/articles/chatgpt-for-drug-development-how-large-language-models-are-changing-drug-discovery/&https://vial.com/blog/articles/chatgpt-for-drug-development-how-large-language-models-are-changing-drug-discovery/?utm_source=organic)

> The launch of ChatGPT was met with a flurry of excitement and the publication of several studies to determine its strengths and potential applications in healthcare and clinical research, as well as its limitations, risks, and consequences of widespread, unchecked use. The tone appears to be cautious optimism as researchers raise ethical concerns, the risk of artificial hallucinations, and the uncertainty of how ChatGPT will perform in real-world situations, amongst others. In addition, Arif et al. (2023) cite a lack of critical thinking and the inclusion of redundant information as reasons why scientific experts and journals reject ChatGPT.
>
> ChatGPT 的推出引起了一阵兴奋，并发表了几项研究以确定其在医疗保健和临床研究中的优势和潜在应用，以及其局限性、风险和广泛、未经检查的使用的后果。 基调似乎是谨慎乐观的，因为研究人员提出了道德问题、人为幻觉的风险以及 ChatGPT 在现实世界中的表现的不确定性等。 此外，Arif 等人。 (2023) 引用缺乏批判性思维和包含冗余信息作为科学专家和期刊拒绝 ChatGPT 的原因。
>
> **The Application of ChatGPT in Drug Development**
>
> Medical institutions and clinical research organizations (CROs) can transform the landscape of clinical research by leveraging AI algorithms and machine learning. The application of AI models opens up opportunities to analyze massive amounts of unstructured data, expanding data-based research and simplifying the research process. To support drug development, ChatGPT can potentially predict drug-target interactions, speed up the identification of potential drug candidates, and help identify opportunities for drug repurposing.
>
> 医疗机构和临床研究组织 (CRO) 可以利用人工智能算法和机器学习来改变临床研究的格局。 人工智能模型的应用为分析大量非结构化数据、扩展基于数据的研究和简化研究过程提供了机会。 为了支持药物开发，ChatGPT 可以潜在地预测药物与靶标的相互作用，加快潜在候选药物的识别，并帮助确定药物再利用的机会。
>
> **Limitations and Risks of Using ChatGPT for Drug Discovery**
> 
    >
    > ChatGPT’s output can be incorrect or biased, e.g., citing non-existent references or perpetuating sexist stereotypes
    >
    > ChatGPT 的输出可能不正确或有偏见，例如，引用不存在的参考资料或延续性别歧视的刻板印象
    > 
    > erroneous ChatGPT outputs used to train future iterations of the model will be amplified
    > 
    > inaccuracies in ChatGPT outputs could fuel the spread of misinformation.
    > 
    > risk of introducing errors and plagiarized content into publications which in the long run may negatively impact research and health policy decisions 
    > 
    > users can circumvent OpenAI guardrails set up to minimize these risks.